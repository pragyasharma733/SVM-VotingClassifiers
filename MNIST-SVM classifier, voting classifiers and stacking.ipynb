{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb597c1",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d256c1f",
   "metadata": {},
   "source": [
    "SVM classification and regression on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001e4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X_train = mnist[\"data\"][:60000]\n",
    "X_test  = mnist[\"data\"][60000:]\n",
    "y_train = mnist[\"target\"][:60000]\n",
    "y_test  = mnist[\"target\"][60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a05712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "N = 2000\n",
    "split_obj = StratifiedShuffleSplit(n_splits=1,\n",
    "                               test_size=N/60000, random_state=42)\n",
    "for other_idx, subsample_idx in split_obj.split(X_train, y_train):\n",
    "    X = X_train[subsample_idx]\n",
    "    y = y_train[subsample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83d7f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearSVC(max_iter=50000), n_jobs=-1,\n",
       "             param_grid=[{'C': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06,\n",
       "                                1e-07, 1e-08, 1e-09]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "param= []\n",
    "\n",
    "for i in range(10):\n",
    "    param.append(10**-i)\n",
    "\n",
    "param_grid = [{'C': param}]\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=50000)\n",
    "\n",
    "grid_search = GridSearchCV(lin_svc, param_grid, cv=3,\n",
    "                           scoring='accuracy',n_jobs=-1)\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a30ea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator:  LinearSVC(C=1e-07, max_iter=50000)\n",
      "Best Score:  0.8624974299636969\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Estimator: \",grid_search.best_estimator_)\n",
    "print(\"Best Score: \",grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36605aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(max_iter=50000),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002838016C910>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000283801703D0>},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc_rbf = SVC(max_iter=50000)\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svc_rbf, param_distributions, n_iter=10, cv=3, scoring='accuracy', random_state = 42 )\n",
    "rnd_search_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319e773d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=4.745401188473625, gamma=0.07969454818643928, max_iter=50000)\n",
      "0.11250005627816723\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_estimator_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030d4ac",
   "metadata": {},
   "source": [
    "Grid Search estimator provides a better score in comparison to Randomized Grid Search estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27bdaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b6c60",
   "metadata": {},
   "source": [
    "# Voting Classifiers and Stacking on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facfba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "M = 6000\n",
    "X_train = mnist[\"data\"][:N]\n",
    "X_val  = mnist[\"data\"][N:M]\n",
    "y_train = mnist[\"target\"][:N]\n",
    "y_val = mnist[\"target\"][N:M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea967b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.939"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "val_pred = rnd_clf.predict(X_val)\n",
    "print(\"Accuracy of random forest classifier on validation set:\")\n",
    "accuracy_score(y_val, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a209a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of extra-trees classifier on validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extra-trees classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ext_clf = ExtraTreesClassifier(n_estimators=100,n_jobs=-1, random_state=42)\n",
    "ext_clf.fit(X_train, y_train)\n",
    "\n",
    "val_pred = ext_clf.predict(X_val)\n",
    "print(\"Accuracy of extra-trees classifier on validation set:\")\n",
    "accuracy_score(y_val, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e70aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost classifier on validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc_clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.2, random_state=42)\n",
    "abc_clf.fit(X_train, y_train)\n",
    "\n",
    "val_pred = abc_clf.predict(X_val)\n",
    "print(\"Accuracy of AdaBoost classifier on validation set:\")\n",
    "accuracy_score(y_val, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e528df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of gradient boosting classifier on validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42)\n",
    "grb_clf.fit(X_train, y_train)\n",
    "\n",
    "val_pred = grb_clf.predict(X_val)\n",
    "print(\"Accuracy of gradient boosting classifier on validation set:\")\n",
    "accuracy_score(y_val, val_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a01b4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting classifier score on val set:  0.923\n",
      "soft voting classifier score on val set:  0.926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard_voting_clf = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf), ('ext', ext_clf), ('abc', abc_clf), ('grb', grb_clf)],\n",
    "    voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "hard_val_pred = hard_voting_clf.predict(X_val)\n",
    "print(\"hard voting classifier score on val set: \", accuracy_score(y_val, hard_val_pred))\n",
    "\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf), ('ext', ext_clf), ('abc', abc_clf), ('grb', grb_clf)],\n",
    "    voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "soft_val_pred = soft_voting_clf.predict(X_val)\n",
    "print(\"soft voting classifier score on val set: \", accuracy_score(y_val, soft_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00291269",
   "metadata": {},
   "source": [
    "Comment: Performance of ensemble model is better than AdaBoost and Gradient Boosting Classifier but worse when compared to random forest and extra trees classifier.\n",
    "\n",
    "The ensemble classifier low accuracy score could be due to very low performance by AdaBoost and Gradient Boosting Classifier, pulling down the entire accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf5de6",
   "metadata": {},
   "source": [
    "**Stacking is an ensemble method in which you train a model (called a blender) to aggregate the result of each predictor into an ensemble prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cef7098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 3., 3.],\n",
       "       [0., 0., 5., 0.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [9., 9., 9., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "estimators = [rnd_clf, ext_clf, abc_clf, grb_clf]\n",
    "pred = np.empty((len(X_train), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    pred[:, index] = cross_val_predict(estimator, X_train, y_train, cv=3)\n",
    "\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df061a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehoten = OneHotEncoder()\n",
    "one_hot_pred=onehoten.fit_transform(pred)\n",
    "one_hot_pred = one_hot_pred.toarray()\n",
    "one_hot_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9c4e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_forest_blender.fit(one_hot_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d9f06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "    \n",
    "X_val_onehoten = onehoten.transform(X_val_predictions)\n",
    "X_val_onehoten = X_val_onehoten.toarray()\n",
    "\n",
    "y_val_pred = rnd_forest_blender.predict(X_val_onehoten)\n",
    "accuracy_score(y_val, y_val_pred)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64414b",
   "metadata": {},
   "source": [
    "Comment: Blender classifier has a better accuracy than voting classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
